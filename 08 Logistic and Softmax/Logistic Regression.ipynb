{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Logistic Regression and SoftMax Regression</h2>\n",
    "\n",
    "In this module, we discuss two classification models: Logistic regression and SoftMax regression.\n",
    "\n",
    "<h3>Binary Logistic Regression</h3>\n",
    "\n",
    "In this example, we use the credit approvement data - the problem is to predict if the credit transaction is approved (+) or not (-). The target is the last column in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  202.0    0  +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g   43.0  560  +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  280.0  824  +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  100.0    3  +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  120.0    0  +"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crx = pd.read_csv('crx.data', header=None)\n",
    "crx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convert '+' and '-' to 1 and 0 for better uses with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.zeros(crx.shape[0])           #create a vector of zeros with size = the data\n",
    "Y[crx[15]=='+'] = 1                  #when the actual target is +, Y is assigned 1\n",
    "crx[15] = Y                          #assign the new labels back to the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Train/Test Split </h4>\n",
    "\n",
    "Recall, the target in this data is column 15, we will use stratified split based on column 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((517, 15), (517,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(crx, crx[15]):\n",
    "    strat_train_set = crx.loc[train_index]\n",
    "    strat_test_set = crx.loc[test_index]\n",
    "    \n",
    "trainX = strat_train_set.loc[:,:14]\n",
    "trainY = strat_train_set.loc[:,15]\n",
    "trainX.shape, trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      object\n",
       "1     float64\n",
       "2     float64\n",
       "3      object\n",
       "4      object\n",
       "5      object\n",
       "6      object\n",
       "7     float64\n",
       "8      object\n",
       "9      object\n",
       "10      int64\n",
       "11     object\n",
       "12     object\n",
       "13    float64\n",
       "14      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Preprocessing</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log transformation is relatively useful in binary classification. We will use FunctionTransformer to conduct log transformation on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of numeric columns\n",
    "#we use '|' to combine condition because we have both int64 and float64 in the columns\n",
    "num_cols = trainX.columns[(trainX.dtypes == np.int64) | (trainX.dtypes == np.float64)]\n",
    "\n",
    "#create a transform function for FunctionTransformer\n",
    "def log_transform(X):                             #input of the function is any dataset X\n",
    "    log_X = np.log(X + 0.1)                       #log of all columns of X, we add 0.1 to avoid log(0)\n",
    "    return np.c_[X,log_X]                         #return X concatenated with log columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build our numeric pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('log transform', FunctionTransformer(log_transform, validate=False)),\n",
    "    ('standardize', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the class pipeline. We will impute with missing category, then OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#get a list of class columns\n",
    "cat_cols = trainX.columns[trainX.dtypes==object]\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='constant',fill_value='missing')),\n",
    "    ('encode', OneHotEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then combine the two pipelines with ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('numeric', num_pipeline, num_cols),\n",
    "    ('class', cat_pipeline, cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, transform the data through the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 57)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX_prc = full_pipeline.fit_transform(trainX)\n",
    "\n",
    "trainX_prc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173, 57)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Similarly for testing data\n",
    "testX = strat_test_set.loc[:,:14]\n",
    "testY = strat_test_set.loc[:,15]\n",
    "\n",
    "testX_prc = full_pipeline.transform(testX)  \n",
    "testX_prc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Modeling with Logistic Regression</h4>\n",
    "\n",
    "Just as any other sklearn models, begin analysis is very easy. First, let's try the default model. I will just consider accuracy and F1 score. You may want to practice with other measurements/curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.874274661508704\n",
      "Cross-Validation Accuracy:  0.8509992382488686\n",
      "Cross-Validation F1:  0.8351177730192719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#create new model\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "#train \n",
    "logistic.fit(trainX_prc, trainY)\n",
    "\n",
    "#get CV accuracy\n",
    "accuracy_3cv = cross_val_score(logistic, trainX_prc, trainY, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "#get prediction for computation of F1 score\n",
    "y_train_pred = cross_val_predict(logistic, trainX_prc, trainY, cv=3)\n",
    "\n",
    "print('Training Accuracy: ', logistic.score(trainX_prc, trainY))\n",
    "print('Cross-Validation Accuracy: ',accuracy_3cv.mean())\n",
    "print('Cross-Validation F1: ', f1_score(trainY, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default model seems to be ok, no significant signs of overfitting. Let's try finetune it.\n",
    "\n",
    "<h4>L2 Regularization</h4>\n",
    "\n",
    "Recall, this is similar to Ridge regression - we add the sum of squares values of coefficients to the training objective. However, the hyperparameter is <b>C</b>, NOT alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=5000, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10,\n",
       "                                50, 100]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1 , 5, 10, 50, 100]}]\n",
    "\n",
    "#the default is l2 anyway, but we can specify it so that the code is clear\n",
    "#logistic regression is also trained iteratively, we can increase max_iter if you see some warning from sklearn\n",
    "logistic = LogisticRegression(penalty='l2', max_iter=5000)\n",
    "\n",
    "grid_search = GridSearchCV(logistic, param_grid, cv=5, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX_prc,trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1}\n",
      "0.856814787154593\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And apply it on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.861271676300578"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_l2_logistic = grid_search.best_estimator_\n",
    "\n",
    "best_l2_logistic.score(testX_prc, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>L1 Regularization</h4>\n",
    "\n",
    "This is similar to LASSO, we add sum of absolute values to the training objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=5000, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l1',\n",
       "                                          random_state=None, solver='liblinear',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10,\n",
       "                                50, 100]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1 , 5, 10, 50, 100]}]\n",
    "\n",
    "#now we need to specify penalty to l1\n",
    "#also, we need to set solver to 'liblinear' because the default solver doesn't support l1\n",
    "logistic = LogisticRegression(penalty='l1', max_iter=5000, solver='liblinear')\n",
    "\n",
    "grid_search = GridSearchCV(logistic, param_grid, cv=5, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX_prc,trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.5}\n",
      "0.8606422703510083\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.861271676300578"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_l1_logistic = grid_search.best_estimator_\n",
    "\n",
    "best_l1_logistic.score(testX_prc, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Elastic Net Regularization</h4>\n",
    "\n",
    "Similar to Elastic Net model in regression, we use both l1 and l2 regularization in the same model. Now we need to finetune both C and l1_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=5000, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='elasticnet',\n",
       "                                          random_state=None, solver='saga',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10,\n",
       "                                50, 100],\n",
       "                          'l1_ratio': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
       "                                       0.9]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now penalty is changed to elasticnet\n",
    "#and we need to change solver to saga\n",
    "logistic = LogisticRegression(penalty='elasticnet', max_iter=5000, solver='saga')\n",
    "\n",
    "param_grid = [{\n",
    "    'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1 , 5, 10, 50, 100],\n",
    "    'l1_ratio': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(logistic, param_grid, cv=5, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX_prc,trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.5, 'l1_ratio': 0.5}\n",
      "0.8625840179238239\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And apply to testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.861271676300578"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_enet_logistic = grid_search.best_estimator_\n",
    "\n",
    "best_enet_logistic.score(testX_prc, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>No-Regularization Model</h4>\n",
    "\n",
    "Finally, let's see how a model without regularization perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8820116054158608\n",
      "Cross-Validation Accuracy:  0.8336357933413989\n",
      "Cross-Validation F1:  0.8138528138528138\n",
      "Testing Accuracy:  0.8497109826589595\n"
     ]
    }
   ],
   "source": [
    "#we need to set penalty to 'none'\n",
    "logistic = LogisticRegression(penalty='none', max_iter=5000)\n",
    "\n",
    "#train \n",
    "logistic.fit(trainX_prc, trainY)\n",
    "\n",
    "#get CV accuracy\n",
    "accuracy_3cv = cross_val_score(logistic, trainX_prc, trainY, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "#get prediction for computation of F1 score\n",
    "y_train_pred = cross_val_predict(logistic, trainX_prc, trainY, cv=3)\n",
    "\n",
    "print('Training Accuracy: ', logistic.score(trainX_prc, trainY))\n",
    "print('Cross-Validation Accuracy: ',accuracy_3cv.mean())\n",
    "print('Cross-Validation F1: ', f1_score(trainY, y_train_pred))\n",
    "print('Testing Accuracy: ', logistic.score(testX_prc, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the CV accuracy and testing accuracy drop more than in other models. The no-regularization model may be overfitting the data slightly\n",
    "\n",
    "<h4>Result Summary</h4>\n",
    "\n",
    "We can summarize all model performances in a table. I'll just focus on accuracy\n",
    "\n",
    "|Model|Training CV Accuracy| Testing Accuracy|\n",
    "|-----|--------------------|-----------------|\n",
    "|No Regularization|0.834|0.850|\n",
    "|L2 Regularization|0.857|0.861|\n",
    "|L1 Regularization|0.861|0.861|\n",
    "|ENet Regularization|0.863|0.861|\n",
    "\n",
    "Except for the no-regularization model which perform slightly worse, all regularized models have very close performance in the training data, and equal performance in the testing data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
