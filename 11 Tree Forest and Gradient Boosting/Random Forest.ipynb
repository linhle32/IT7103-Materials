{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Random Forest</h2>\n",
    "\n",
    "Decision tree, while can be very powerful, also comes with problems like overfitting, unstable... We usually prefer random forest which is a set of decision tree trained on different random subsets of data.\n",
    "\n",
    "<h3>For Classification</h3>\n",
    "\n",
    "Let's try random forest on the credit approval data. As usual, we preprocess the data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((734, 20), (184, 20))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('heart_disease.csv')\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "num_cols = trainX.columns[(trainX.dtypes == np.int64) | (trainX.dtypes == np.float64)]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('standardize', StandardScaler())\n",
    "])\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#get a list of class columns\n",
    "cat_cols = trainX.columns[trainX.dtypes==object]\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='constant',fill_value='missing')),\n",
    "    ('encode', OneHotEncoder())\n",
    "])\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('numeric', num_pipeline, num_cols),\n",
    "    ('class', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "trainX_prc = full_pipeline.fit_transform(trainX)\n",
    "testX_prc = full_pipeline.transform(testX)  \n",
    "\n",
    "trainX_prc.shape, testX_prc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now finetune the random forest model. You need to tune all the parameters that decision tree has, plus n_estimators which is the number of trees in the forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'max_depth': [3, 4, 5], 'max_features': [5, 10, 15],\n",
       "                          'min_samples_leaf': [1, 10, 20, 30, 40],\n",
       "                          'min_samples_split': [2, 10, 20, 30, 40],\n",
       "                          'n_estimators': [5, 10, 20, 50]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{\n",
    "    'n_estimators' : [5, 10, 20, 50],\n",
    "    'max_depth': [3,4,5],\n",
    "    'max_features' : [5, 10, 15],\n",
    "    'min_samples_split' : [2, 10, 20, 30, 40],\n",
    "    'min_samples_leaf' : [1, 10, 20, 30, 40]\n",
    "}]\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX_prc,trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best training model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 5, 'min_samples_leaf': 10, 'min_samples_split': 30, 'n_estimators': 20}\n",
      "0.8692386543658559\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8804347826086957"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt = grid_search.best_estimator_\n",
    "best_dt.score(testX_prc, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being a forest, we can no longer explain the model or visualize it. However, you can see the performance of Random Forest is very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Summarize all Results</h4>\n",
    "\n",
    "Compared to other models so far:\n",
    "\n",
    "|Model|Training CV Accuracy| Testing Accuracy|\n",
    "|-----|--------------------|-----------------|\n",
    "|No Regularization|0.834|0.850|\n",
    "|L2 Regularization|0.857|0.861|\n",
    "|L1 Regularization|0.861|0.861|\n",
    "|ENet Regularization|0.863|0.861|\n",
    "|L1 Linear SVM|0.851|0.861|\n",
    "|L2 Linear SVM|0.853|0.873|\n",
    "|Kernel SVM|0.872|0.867|\n",
    "|Decision Tree|0.858|0.867|\n",
    "|Random Forest|0.88|0.896|\n",
    "\n",
    "As you can see, Random Forest ended up being the best model in both CV training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> For Regression </h3>\n",
    "\n",
    "We will use RandomForestRegressor. Let's revisit the auto-mpg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((298, 7), (100, 7), (298,), (100,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = pd.read_csv('auto-mpg.csv')\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "split = ShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(auto):\n",
    "    train_set = auto.loc[train_index]\n",
    "    test_set = auto.loc[test_index]\n",
    "    \n",
    "trainX = train_set.drop('mpg',axis=1)\n",
    "trainY = train_set['mpg']\n",
    "testX = test_set.drop('mpg',axis=1)\n",
    "testY = test_set['mpg']\n",
    "\n",
    "trainX.shape, testX.shape, trainY.shape, testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipeline for numeric features\n",
    "#we need to impute horsepower\n",
    "num_cols = trainX.columns[:-1] #because the last column is class\n",
    "num_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('standardize', StandardScaler())\n",
    "])\n",
    "\n",
    "#pipeline for class features\n",
    "cat_cols = trainX.columns[-1:] #because the last column is class\n",
    "cat_pipeline = Pipeline([\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "#full pipeline - combine numeric and class pipelines\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('numeric', num_pipeline, num_cols),\n",
    "    ('class', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "trainX_prc = full_pipeline.fit_transform(trainX)\n",
    "testX_prc = full_pipeline.transform(testX)\n",
    "\n",
    "trainX_prc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'max_depth': [3, 4, 5], 'max_features': [5, 7, 9],\n",
       "                          'min_samples_leaf': [1, 10, 20, 30, 40],\n",
       "                          'min_samples_split': [2, 10, 20, 30, 40],\n",
       "                          'n_estimators': [5, 10, 20, 50]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='r2', verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "param_grid = [{\n",
    "    'n_estimators' : [5, 10, 20, 50],\n",
    "    'max_depth': [3,4,5],\n",
    "    'max_features' : [5, 7, 9],\n",
    "    'min_samples_split' : [2, 10, 20, 30, 40],\n",
    "    'min_samples_leaf' : [1, 10, 20, 30, 40]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(rfr, param_grid, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX_prc,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 9, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "0.8542226762851193\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8774914474874439"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt = grid_search.best_estimator_\n",
    "best_dt.score(testX_prc, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Result Summary</h4>\n",
    "\n",
    "|Model|Training CV R2| Testing R2|\n",
    "|-----|--------------|-----------|\n",
    "|Ridge|0.852         |0.893      |\n",
    "|LASSO|0.851         |0.895      |\n",
    "|ENet |0.851         |0.895      |\n",
    "|SVR  |0.864         |0.905      |\n",
    "|DTR  |0.823         |0.867      |\n",
    "|RFR  |0.854         |0.877      |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
