{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Polynomial Regression </h3>\n",
    "\n",
    "To add polynomial features to the data, we use PolynomialFeatures - remember to set the polynomial degree\n",
    "\n",
    "For example, to add 2nd-degree features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  0.,  1.],\n",
       "       [ 2.,  3.,  4.,  6.,  9.],\n",
       "       [ 4.,  5., 16., 20., 25.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "X = np.array([[0, 1],\n",
    "              [2, 3],\n",
    "              [4, 5]])\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "X_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or 3rd-degree features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   1.,   0.,   0.,   1.,   0.,   0.,   0.,   1.],\n",
       "       [  2.,   3.,   4.,   6.,   9.,   8.,  12.,  18.,  27.],\n",
       "       [  4.,   5.,  16.,  20.,  25.,  64.,  80., 100., 125.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_3 = PolynomialFeatures(degree=3, include_bias=False)\n",
    "\n",
    "X_poly_3 = poly_3.fit_transform(X)\n",
    "\n",
    "X_poly_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Adding Polynomial Features in a Pipeline</h3>\n",
    "\n",
    "In a real analysis, we can add the new features as another step in our pipeline, for example, in the auto-mpg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((298, 7), (100, 7), (298,), (100,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "auto = pd.read_csv('auto-mpg.csv')\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "split = ShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(auto):\n",
    "    train_set = auto.loc[train_index]\n",
    "    test_set = auto.loc[test_index]\n",
    "    \n",
    "trainX = train_set.drop('mpg',axis=1)\n",
    "trainY = train_set['mpg']\n",
    "testX = test_set.drop('mpg',axis=1)\n",
    "testY = test_set['mpg']\n",
    "\n",
    "trainX.shape, testX.shape, trainY.shape, testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#pipeline for numeric features\n",
    "#we need to impute horsepower\n",
    "num_cols = trainX.columns[:-1] #because the last column is class\n",
    "num_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('standardize', StandardScaler())\n",
    "])\n",
    "\n",
    "#pipeline for class features\n",
    "cat_cols = trainX.columns[-1:] #because the last column is class\n",
    "cat_pipeline = Pipeline([\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "#full pipeline - combine numeric and class pipelines\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('numeric', num_pipeline, num_cols),\n",
    "    ('class', cat_pipeline, cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298, 31)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX_poly2 = full_pipeline.fit_transform(trainX)\n",
    "trainX_poly2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adding polynomial features, we fit a linear regression model like normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly Reg 2nd-degree Train R2:  0.8000350958113276\n",
      "Poly Reg 2nd-degree CV MSE:  17.706947104069584\n",
      "Poly Reg 2nd-degree CV R2:  0.7064347089744643\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(trainX_poly2,trainY)\n",
    "\n",
    "mse_lr_cv = - cross_val_score(poly_reg, trainX_poly2, trainY, cv=5, scoring='neg_mean_squared_error')\n",
    "r2_lr_cv = cross_val_score(poly_reg, trainX_poly2, trainY, cv=5, scoring='r2')\n",
    "\n",
    "print('Poly Reg 2nd-degree Train R2: ', poly_reg.score(trainX_poly2,trainY))\n",
    "print('Poly Reg 2nd-degree CV MSE: ', mse_lr_cv.mean())\n",
    "print('Poly Reg 2nd-degree CV R2: ', r2_lr_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the training R2 is much better than the cross-validation R2. What does this means?\n",
    "\n",
    "It turns out, adding polynomial features is a very easy way to overfit the training data; the higher the degree, the easier it gets to overfit.\n",
    "\n",
    "Let's see a 3rd-degree polynomial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298, 87)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline_2 = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('poly', PolynomialFeatures(degree=3)),\n",
    "    ('standardize', StandardScaler())\n",
    "])\n",
    "\n",
    "#full pipeline - combine numeric and class pipelines\n",
    "full_pipeline_2 = ColumnTransformer([\n",
    "    ('numeric', num_pipeline_2, num_cols),\n",
    "    ('class', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "trainX_poly3 = full_pipeline_2.fit_transform(trainX)\n",
    "trainX_poly3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly Reg 3rd-degree Train R2:  0.8482560536976587\n",
      "Poly Reg 3rd-degree CV MSE:  85.82578213135113\n",
      "Poly Reg 3rd-degree CV R2:  -0.41270046586832\n"
     ]
    }
   ],
   "source": [
    "poly_reg.fit(trainX_poly3,trainY)\n",
    "\n",
    "mse_lr_cv = - cross_val_score(poly_reg, trainX_poly3, trainY, cv=5, scoring='neg_mean_squared_error')\n",
    "r2_lr_cv = cross_val_score(poly_reg, trainX_poly3, trainY, cv=5, scoring='r2')\n",
    "\n",
    "print('Poly Reg 3rd-degree Train R2: ', poly_reg.score(trainX_poly3,trainY))\n",
    "print('Poly Reg 3rd-degree CV MSE: ', mse_lr_cv.mean())\n",
    "print('Poly Reg 3rd-degree CV R2: ', r2_lr_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, training R2 is even higher than before, and cross-validation R2 is negative now, all of which suggests this model is overfitting the data even more severely. \n",
    "\n",
    "Let's try a regular linear model without polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298, 9)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline_3 = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('standardize', StandardScaler())\n",
    "])\n",
    "\n",
    "#full pipeline - combine numeric and class pipelines\n",
    "full_pipeline_3 = ColumnTransformer([\n",
    "    ('numeric', num_pipeline_3, num_cols),\n",
    "    ('class', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "trainX_ln = full_pipeline_3.fit_transform(trainX)\n",
    "trainX_ln.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Reg Train R2:  0.8172751189834604\n",
      "Linear Reg CV MSE:  12.138420248599349\n",
      "Linear Reg CV R2:  0.8030148839899887\n"
     ]
    }
   ],
   "source": [
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(trainX_ln,trainY)\n",
    "\n",
    "mse_lr_cv = - cross_val_score(poly_reg, trainX_ln, trainY, cv=5, scoring='neg_mean_squared_error')\n",
    "r2_lr_cv = cross_val_score(poly_reg, trainX_ln, trainY, cv=5, scoring='r2')\n",
    "\n",
    "print('Linear Reg Train R2: ', linear_reg.score(trainX_ln,trainY))\n",
    "print('Linear Reg CV MSE: ', mse_lr_cv.mean())\n",
    "print('Linear Reg CV R2: ', r2_lr_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ridge Regression</h3>\n",
    "\n",
    "We use the Ridge class, also from the sklearn.linear_model module. A default Ridge regression model has alpha=1.\n",
    "\n",
    "Let's try the model on the 2nd-degree polynomial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly Reg Train R2:  0.8713112281784805\n",
      "Poly Reg CV MSE:  9.18003939637259\n",
      "Poly Reg CV R2:  0.8507888466222286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_reg = Ridge()\n",
    "\n",
    "ridge_reg.fit(trainX_poly2,trainY)\n",
    "\n",
    "mse_lr_cv = - cross_val_score(ridge_reg, trainX_poly2, trainY, cv=5, scoring='neg_mean_squared_error')\n",
    "r2_lr_cv = cross_val_score(ridge_reg, trainX_poly2, trainY, cv=5, scoring='r2')\n",
    "\n",
    "print('Poly Reg Train R2: ', ridge_reg.score(trainX_poly2,trainY))\n",
    "print('Poly Reg CV MSE: ', mse_lr_cv.mean())\n",
    "print('Poly Reg CV R2: ', r2_lr_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the immediate improvement, the model no longer overfits, and even gets better than all previous linear models. However, adding more features may still make the model worse, for example, in the 3rd-degree polynomial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly Reg Train R2:  0.8810875212915859\n",
      "Poly Reg CV MSE:  9.33117703231586\n",
      "Poly Reg CV R2:  0.8479611655203125\n"
     ]
    }
   ],
   "source": [
    "ridge_reg.fit(trainX_poly3,trainY)\n",
    "\n",
    "mse_lr_cv = - cross_val_score(ridge_reg, trainX_poly3, trainY, cv=5, scoring='neg_mean_squared_error')\n",
    "r2_lr_cv = cross_val_score(ridge_reg, trainX_poly3, trainY, cv=5, scoring='r2')\n",
    "\n",
    "print('Poly Reg Train R2: ', ridge_reg.score(trainX_poly3,trainY))\n",
    "print('Poly Reg CV MSE: ', mse_lr_cv.mean())\n",
    "print('Poly Reg CV R2: ', r2_lr_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in the linear data, we have very similar result to OLS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly Reg Train R2:  0.8171790286982343\n",
      "Poly Reg CV MSE:  12.107294352932252\n",
      "Poly Reg CV R2:  0.803609988247809\n"
     ]
    }
   ],
   "source": [
    "ridge_reg = Ridge()\n",
    "\n",
    "ridge_reg.fit(trainX_ln,trainY)\n",
    "\n",
    "mse_lr_cv = - cross_val_score(ridge_reg, trainX_ln, trainY, cv=5, scoring='neg_mean_squared_error')\n",
    "r2_lr_cv = cross_val_score(ridge_reg, trainX_ln, trainY, cv=5, scoring='r2')\n",
    "\n",
    "print('Poly Reg Train R2: ', ridge_reg.score(trainX_ln,trainY))\n",
    "print('Poly Reg CV MSE: ', mse_lr_cv.mean())\n",
    "print('Poly Reg CV R2: ', r2_lr_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mention, alpha is a hyper-parameter you need to finetune. We can use grid-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=None, normalize=False, random_state=None,\n",
       "                             solver='auto', tol=0.001),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5,\n",
       "                                    10, 50, 100]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='r2', verbose=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{'alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1 , 5, 10, 50, 100]}]\n",
    "\n",
    "grid_search = GridSearchCV(ridge_reg, param_grid, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX_poly2,trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best alpha is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.05}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8521680350488623"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see the R2 for each value of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8480419603031771 {'alpha': 0.001}\n",
      "0.8510845383633667 {'alpha': 0.005}\n",
      "0.8514615136150165 {'alpha': 0.01}\n",
      "0.8521680350488623 {'alpha': 0.05}\n",
      "0.8520849294753257 {'alpha': 0.1}\n",
      "0.8511228624260276 {'alpha': 0.5}\n",
      "0.8507888466222286 {'alpha': 1}\n",
      "0.8488728987652407 {'alpha': 5}\n",
      "0.845693335415354 {'alpha': 10}\n",
      "0.8271070063960442 {'alpha': 50}\n",
      "0.8104032968789869 {'alpha': 100}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While alpha=0.05 offers the best R2, it is not much higher than other values <= 1. However, if your project focuses on prediction performance, you may want as high R2 as possible.\n",
    "\n",
    "We can get the best model by using best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ridge_gs = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try the best Ridge model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89303597884887"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remember, when use pipeline to transform testing data, we don't use fit_transform() any more\n",
    "testX_poly2 = full_pipeline.transform(testX)\n",
    "\n",
    "best_ridge_gs.score(testX_poly2, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we obtain very high R2 in testing data :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>LASSO</h3>\n",
    "\n",
    "Is very similar to Ridge regression. We use the Lasso class from linear_model module. The default alpha is also 1. 2nd-degree polynomial data seems to be the best feature set, so I'll just consider that set from now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly Reg Train R2:  0.7837047482136399\n",
      "Poly Reg CV MSE:  13.737136011228907\n",
      "Poly Reg CV R2:  0.778124184302442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_reg = Lasso()\n",
    "\n",
    "lasso_reg.fit(trainX_poly2,trainY)\n",
    "\n",
    "mse_lr_cv = - cross_val_score(lasso_reg, trainX_poly2, trainY, cv=5, scoring='neg_mean_squared_error')\n",
    "r2_lr_cv = cross_val_score(lasso_reg, trainX_poly2, trainY, cv=5, scoring='r2')\n",
    "\n",
    "print('Poly Reg Train R2: ', lasso_reg.score(trainX_poly2,trainY))\n",
    "print('Poly Reg CV MSE: ', mse_lr_cv.mean())\n",
    "print('Poly Reg CV R2: ', r2_lr_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very impressive performance, let's try finetuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 549.1439828607947, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 412.5050948913396, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 494.34983721949607, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 563.8567615775291, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 449.4917219746244, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.59756672942217, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.865646340397234, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.089562940529731, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22.008520122979007, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.202312455832043, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.7342534691933906, tolerance: 1.5106677573221763\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=5000, normalize=False, positive=False,\n",
       "                             precompute=False, random_state=None,\n",
       "                             selection='cyclic', tol=0.0001, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5,\n",
       "                                    10, 50, 100]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='r2', verbose=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lasso model are trained iteratively, so you also have to choose the maximum number of iterations with max_iter\n",
    "#if you see a warning about convergence (like showing below)\n",
    "#you may increase max_iter\n",
    "#however it is not always necessary\n",
    "lasso_reg = Lasso(max_iter=5000)\n",
    "\n",
    "param_grid = [{'alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1 , 5, 10, 50, 100]}]\n",
    "\n",
    "grid_search = GridSearchCV(lasso_reg, param_grid, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX_poly2,trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R2 of all alpha values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8490242123571088 {'alpha': 0.001}\n",
      "0.8508598661674691 {'alpha': 0.005}\n",
      "0.8508822626025525 {'alpha': 0.01}\n",
      "0.8450617682283834 {'alpha': 0.05}\n",
      "0.8285816864055413 {'alpha': 0.1}\n",
      "0.8023405941693722 {'alpha': 0.5}\n",
      "0.778124184302442 {'alpha': 1}\n",
      "0.2655134364946863 {'alpha': 5}\n",
      "-0.01511192028637649 {'alpha': 10}\n",
      "-0.01511192028637649 {'alpha': 50}\n",
      "-0.01511192028637649 {'alpha': 100}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the best alpha value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can obtain best model with best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lasso = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And test it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8952667599256074"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lasso.score(testX_poly2, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the result is very similar to Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Elastic Net</h3>\n",
    "\n",
    "The default alpha is 1, and rho is 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly Reg Train R2:  0.7822991655202127\n",
      "Poly Reg CV MSE:  13.83954994256914\n",
      "Poly Reg CV R2:  0.776794597461407\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "enet = ElasticNet()\n",
    "\n",
    "enet.fit(trainX_poly2,trainY)\n",
    "\n",
    "mse_lr_cv = - cross_val_score(enet, trainX_poly2, trainY, cv=5, scoring='neg_mean_squared_error')\n",
    "r2_lr_cv = cross_val_score(enet, trainX_poly2, trainY, cv=5, scoring='r2')\n",
    "\n",
    "print('Poly Reg Train R2: ', enet.score(trainX_poly2,trainY))\n",
    "print('Poly Reg CV MSE: ', mse_lr_cv.mean())\n",
    "print('Poly Reg CV R2: ', r2_lr_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, not very impressive performance before finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 943.9988561677949, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 901.8842229289004, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 830.5124412332281, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 958.1739053909638, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 932.0198903504614, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 919.6697596085037, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 864.3741709940427, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 804.0932209552265, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 930.3534030308139, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 907.5517501901007, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 896.5437439017277, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 829.1468246164095, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 779.5897202601968, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 906.1564041665775, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 884.251540520108, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 874.3341320229994, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 800.1157949821136, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 756.7844738341062, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 884.1052914192563, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.6120021158874, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 852.7941274519651, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 779.695112626843, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 735.3380090315445, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 863.8189151814281, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 842.2747044298704, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 832.2437885619225, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 762.6861238221081, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 715.1676381705934, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 844.9365643101186, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 822.8069137506004, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 817.3688279339113, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 748.0676910644751, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 693.2127489821646, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 827.1183091119685, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 801.7188680369683, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 808.4272172023082, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 738.038498677226, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 682.3662031173757, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 810.0086059744526, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 784.712155353396, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 801.2636838287768, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 732.5501773113813, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 673.8090223361672, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 793.2444483456026, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 766.7888600368069, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 758.2740291335153, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 643.235871113081, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 670.5567268858621, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 698.466876414313, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 749.7866601746634, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 580.8160081977699, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 448.29299189556536, tolerance: 1.5381773487394963\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 497.342881151287, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 461.9908627165962, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 549.2123111908281, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 456.8897536081696, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 305.0417778295314, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 351.19757412503816, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 303.00265507926804, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 409.40140714660924, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 320.87833083818157, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 276.35391730179845, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 243.06553619243107, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 257.2464037841439, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 394.42465093992735, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 184.09496657371005, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 254.11802349510106, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 168.97349038173343, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 255.26479923718, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 403.5259210793819, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 147.35259721954344, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 152.33046685522095, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162.6449121539888, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 271.2351872179521, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 409.75548264293, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 151.26490234088283, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 105.57086006149757, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 199.32222652436087, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 264.44383559202765, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 395.68459257453117, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 305.4782445193547, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 128.35927267924558, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 254.27435547419577, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 258.9356940838302, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 370.6008668392004, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 237.17087924990483, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185.30150182164994, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 285.7125988309948, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 277.3830804385086, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 287.0940139247481, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 439.72095598885903, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 441.41194089408543, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 322.08844687425744, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 100.54811672471715, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 249.76127973470568, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161.40924138484593, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 127.73912763310659, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 94.7674020187385, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 83.40437395403796, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 150.95516180543336, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 83.31434156686146, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.03516824947246, tolerance: 1.5381773487394963\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.69199023285978, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53.618959350570776, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.73720495879434, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97421036592391, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 78.10433187690705, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.64973069116172, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.386342912290957, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 90.17724886387532, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.8087872336846, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 59.88088417066592, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53.49999795098847, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 30.100974721006196, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96.3566896388129, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53.8878220482768, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.30938265227883, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64.9406639859551, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.893674860329156, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58.919486260316035, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64.5324143470666, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.878720138096014, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 59.67631968915407, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58.20139107277578, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35.401687480934015, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.52176910527237, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.485600772817406, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 60.93687179987819, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.94852149376493, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.985854844429014, tolerance: 1.5106677573221763\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25.649201091488294, tolerance: 1.5077993949579833\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35.43130148173964, tolerance: 1.5381773487394963\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.189597572857565, tolerance: 1.3696142184873954\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 30.147337084742276, tolerance: 1.4991293221757322\n",
      "  positive)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.03047845042897, tolerance: 1.5106677573221763\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 694.053601255681, tolerance: 1.8574045234899328\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                                  l1_ratio=0.5, max_iter=1000, normalize=False,\n",
       "                                  positive=False, precompute=False,\n",
       "                                  random_state=None, selection='cyclic',\n",
       "                                  tol=0.0001, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5,\n",
       "                                    10, 50, 100],\n",
       "                          'l1_ratio': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
       "                                       0.9]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='r2', verbose=0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the rho paramter is named l1_ratio in sklearn\n",
    "param_grid = [{\n",
    "    'alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1 , 5, 10, 50, 100],\n",
    "    'l1_ratio': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(enet, param_grid, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "grid_search.fit(trainX_poly2,trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are too many models to look at individually now, we will just focus on the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.005, 'l1_ratio': 0.2}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8507592522514302"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the best Elastic-net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_enet = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And test it on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8947727104157833"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_enet.score(testX_poly2, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sum up, the three best models' R2:\n",
    "\n",
    "|Model|Training CV R2| Testing R2|\n",
    "|-----|--------------|-----------|\n",
    "|Ridge|0.852         |0.893      |\n",
    "|LASSO|0.851         |0.895      |\n",
    "|ENet |0.851         |0.895      |\n",
    "\n",
    "Which are very similar in both training and testing data. Depending on the data, these models' performance may vary more, but you should not expect to see tremendous differences. After all, all three are different versions of linear regression models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
